{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "material-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from datetime import date\n",
    "import json\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import jellyfish as jf\n",
    "from urllib.parse import urlparse\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "unknown-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.headless = False\n",
    "DRIVER_PATH = './chromedriver_win32/chromedriver.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "educational-delaware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_exists_by_xpath(driver, xpath):\n",
    "    try:\n",
    "        driver.find_element_by_xpath(xpath)\n",
    "    except NoSuchElementException:\n",
    "        return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "higher-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_punc(s):\n",
    "    keep = string.ascii_letters + ' ' + str(u'\\u00D7')\n",
    "    return ''.join([c for c in s if c in keep])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "therapeutic-electricity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plant_name_check(plant_name_1, plant_name_2, max_lev_dist=3):\n",
    "    n1 = no_punc(plant_name_1).lower()\n",
    "    n2 = no_punc(plant_name_2).lower()\n",
    "\n",
    "    # print(n1, n2)\n",
    "    \n",
    "    # First check if names are the same (save some work if we are very lucky!)\n",
    "    if n1 == n2:\n",
    "        return 1\n",
    "    else:\n",
    "        l1 = n1.split()\n",
    "        l2 = n2.split()        \n",
    "        # Check if all of the words in the queries plant name are in the found plant name...\n",
    "        _1_is_in_2 = 1\n",
    "        for w in l1:\n",
    "            if not w in(l2):\n",
    "                 _1_is_in_2 = 0\n",
    "         # ...and visa versa       \n",
    "        _2_is_in_1 = 1\n",
    "        for w in l2:\n",
    "            if not w in(l1):\n",
    "                 _2_is_in_1 = 0\n",
    "        if _1_is_in_2 or _2_is_in_1:\n",
    "            return 2\n",
    "        # Repeat first comparison, but strip any trailing s to account for possible plurals (e.g. camellias not camellia)\n",
    "        _1_is_in_2_s = 1\n",
    "        l2_s = []\n",
    "        [ l2_s.append(w.rstrip('s')) for w in l2 ]\n",
    "        for w in l1:\n",
    "            if not w.rstrip('s') in(l2_s):\n",
    "                 _1_is_in_2_s = 0\n",
    "        if _1_is_in_2_s:\n",
    "            return 2.5\n",
    "        # Get Levenshtein distance\n",
    "        if jf.levenshtein_distance(n1,n2) <= max_lev_dist:\n",
    "            return 3\n",
    "        else:\n",
    "            return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "prompt-presence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rhs_google_map(driver, rhs_id, botanical_name, common_name):\n",
    "    \n",
    "    # Search for plant_name on google shopping\n",
    "    plant_name_query = '+'.join(no_punc(botanical_name).split())\n",
    "    url = 'https://www.google.co.uk/search?q=' + plant_name_query + '&tbm=shop'\n",
    "    driver.get(url)\n",
    "    print(driver.current_url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Handle cookie consent\n",
    "    if driver.current_url.find('consent') > 0:\n",
    "        print('Cookie consent')\n",
    "        agree_button = WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.XPATH,'//div[@class=\"VfPpkd-RLmnJb\"]')))\n",
    "        agree_button.click()\n",
    "\n",
    "    #time.sleep(60)\n",
    "    print(driver.current_url)  \n",
    "    # Find list of matching search results\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    # Are the results in 'grid' format...\n",
    "    results_html = soup.find(\"div\", {\"class\": \"sh-pr__product-results-grid\"})\n",
    "    if results_html is not None:\n",
    "        #print(\"grid format\")\n",
    "        results_list = results_html.find_all(\"div\", {\"class\": \"sh-dgr__gr-auto sh-dgr__grid-result\"})\n",
    "        match_list = []\n",
    "        [match_list.append(i) for i in results_list if ( ( plant_name_check(botanical_name,i.find(\"h4\", {\"class\":\"A2sOrd\"}).text) < 4 ) or ( plant_name_check(common_name,i.find(\"h4\", {\"class\":\"A2sOrd\"}).text) < 4) )]\n",
    "    else: \n",
    "        # Are the results in list format...\n",
    "        results_html = soup.find(\"div\", {\"class\": \"sh-pr__product-results\"})\n",
    "        if results_html is not None:\n",
    "            #print(\"list format\")\n",
    "            results_list = results_html.find_all(\"div\", {\"class\": \"sh-dlr__list-result\"})\n",
    "            match_list = []\n",
    "            [match_list.append(i) for i in results_list if ( ( plant_name_check(botanical_name,i.find(\"h3\", {\"class\":\"xsRiS\"}).text) < 4 ) or ( plant_name_check(common_name,i.find(\"h3\", {\"class\":\"xsRiS\"}).text) < 4) )]\n",
    "        else:\n",
    "            print(\"Did not recognise the format of the shopping search results on page \" + driver.current_url)\n",
    "            match_list = []\n",
    "    \n",
    "    # Extract data and return as list of dict\n",
    "    rhs_google_map_list = []\n",
    "    rhs_google_map = {}\n",
    "    for p in match_list:\n",
    "        rhs_google_map = {}        \n",
    "        rhs_google_map[\"rhs_id\"] = rhs_id\n",
    "        rhs_google_map[\"google_id_type\"] = \"data-docid\"\n",
    "        rhs_google_map[\"google_id\"] = p.get('data-docid')\n",
    "        rhs_google_map[\"google_product_url\"] = pre+rhs_google_map[\"google_id\"]\n",
    "        rhs_google_map[\"query_date\"] = date.today().strftime(\"%d-%b-%Y\")\n",
    "        rhs_google_map_list.append(rhs_google_map)\n",
    "\n",
    "    return rhs_google_map_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "tracked-supervisor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_buying_options(driver, url, pid):\n",
    "    \n",
    "    # Go to product page and extract info\n",
    "    driver.get(url)\n",
    "    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    \n",
    "    buying_options_list = []\n",
    "    buying_options = {}\n",
    "    \n",
    "    # product-level\n",
    "    google_product_title = soup.find(\"span\", {\"class\":\"BvQan sh-t__title-pdp sh-t__title translate-content\"}).text\n",
    "    google_product_desc = soup.find(\"span\", {\"class\":\"sh-ds__trunc-txt translate-content\"}).text\n",
    "    today = date.today().strftime(\"%d-%b-%Y\")\n",
    "    \n",
    "    # per buying option\n",
    "    # first check that the buying options table is present and structured as expected\n",
    "    if soup.find(\"table\", {\"class\":\"dOwBOc\"}) is not None:\n",
    "        #print(\"found buying options table\")\n",
    "        headers = soup.find(\"tr\", {\"class\":\"sh-osd__headers\"}).find_all(\"th\")\n",
    "        if headers is not None:\n",
    "            #print(\"found \" + str(len(headers)) + \" items in table headers row\" )\n",
    "            if headers[0].text != \"Sold by\":\n",
    "                good = False\n",
    "            elif headers[1].text != \"Details & special offers\":\n",
    "                good = False\n",
    "            elif headers[2].text != \"Item price\":\n",
    "                good = False\n",
    "            elif headers[3].text != \"Total price\":\n",
    "                good = False\n",
    "            else:\n",
    "                good = True\n",
    "            if good:\n",
    "                #print(\"table headers as expected\")\n",
    "                body = soup.find(\"tbody\", {\"id\":\"sh-osd__online-sellers-cont\"})\n",
    "                rows = body.find_all(\"tr\",recursive=False)\n",
    "                num_rows = len(rows)            \n",
    "                for r in rows:\n",
    "                    buying_options = {}\n",
    "                    cells = r.find_all(\"td\",recursive=False)\n",
    "                    buying_options[\"merchant_name\"] = cells[0].find(\"a\", {\"class\":\"sh-osd__seller-link shntl\"}).find(\"span\").text\n",
    "                    buying_options[\"details_and_offers\"] = cells[1].text\n",
    "                    buying_options[\"item_price\"] = cells[2].text\n",
    "                    buying_options[\"total_price\"] = cells[3].find(\"div\", {\"class\":\"sh-osd__total-price\"}).text\n",
    "                    href = cells[0].find(\"a\", {\"class\":\"sh-osd__seller-link shntl\"})[\"href\"]\n",
    "                    driver.get(\"http://www.google.com\" + href)\n",
    "                    buying_options[\"merchant_url\"] =  driver.current_url\n",
    "                    buying_options[\"merchant_netloc\"] = urlparse(driver.current_url)[1]\n",
    "                    buying_options[\"query_date\"] = today\n",
    "                    buying_options[\"google_product_title\"] = google_product_title\n",
    "                    buying_options[\"google_product_desc\"] = google_product_desc\n",
    "                    buying_options[\"google_id\"] = pid\n",
    "                    buying_options_list.append(buying_options)\n",
    "            \n",
    "    else:\n",
    "        buying_options[\"merchant_name\"] = \"\"\n",
    "        buying_options[\"details_and_offers\"] = \"\"\n",
    "        buying_options[\"item_price\"] = \"\"\n",
    "        buying_options[\"total_price\"] = \"\"\n",
    "        buying_options[\"merchant_url\"] =  \"\"\n",
    "        buying_options[\"merchant_netloc\"] = \"\"\n",
    "        buying_options[\"query_date\"] = today\n",
    "        buying_options[\"google_product_title\"] = google_product_title\n",
    "        buying_options[\"google_product_desc\"] = google_product_desc\n",
    "        buying_options[\"google_id\"] = pid\n",
    "        buying_options_list.append(buying_options)\n",
    "        \n",
    "    return buying_options_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "opened-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    driver = webdriver.Chrome(executable_path=DRIVER_PATH, options=options)\n",
    "    \n",
    "    # Read input file\n",
    "    infile = 'plants_veryshort.txt'\n",
    "    \n",
    "    # read file\n",
    "    with open(infile, 'r') as infile:\n",
    "        indata=infile.read()\n",
    "\n",
    "    # parse file\n",
    "    plantlist = json.loads(indata)\n",
    "    n = len(plantlist['data'])\n",
    "    \n",
    "    try:\n",
    "        rhs_google_map = []\n",
    "        google_buying_options = []\n",
    "        #with open(\"testmap.txt\", 'w') as fm, open(\"testbuying.txt\", 'w') as fb:\n",
    "        for i, plant in enumerate(plantlist['data']):\n",
    "            time.sleep(5)\n",
    "            print('Processing plant ' + str(i+1) + ' of ' + str(n) + '.')\n",
    "            try:\n",
    "                products = get_rhs_google_map(driver, plant['rhs_id'], plant['botanical_name'], plant['common_name'])\n",
    "            except:\n",
    "                print('Unable to get google products for plant ' + str(plant['rhs_id']))\n",
    "            else:\n",
    "                #fm.write(json.dump(products))\n",
    "                rhs_google_map.extend(products)\n",
    "                for product in products:\n",
    "                    try:\n",
    "                        buying_options = get_buying_options(driver, product[\"google_product_url\"], product[\"google_id\"])\n",
    "                    except:\n",
    "                        print('Unable to get buying options from ' + str(product[\"google_product_url\"]))\n",
    "                    else:\n",
    "                        google_buying_options.extend(buying_options)\n",
    "                        #fb.write(json.dump(buying_options))\n",
    "\n",
    "        dfmap = pd.DataFrame(rhs_google_map)        \n",
    "        dfmap.to_json(path_or_buf='testmap.txt',orient='table',index=False)\n",
    "\n",
    "        dfbuying = pd.DataFrame(google_buying_options)        \n",
    "        dfbuying.to_json(path_or_buf='testbuying.txt',orient='table',index=False)\n",
    "    except:\n",
    "        pass\n",
    "    finally:\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "thorough-sport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing plant 1 of 1.\n",
      "https://consent.google.co.uk/m?continue=https://www.google.co.uk/search%3Fq%3DCamellia%2B%25C3%2597%2Bwilliamsii%2BETR%2BCarlyon%26tbm%3Dshop&gl=GB&m=0&pc=srp&hl=en&src=1\n",
      "Cookie consent\n",
      "https://www.google.co.uk/search?q=Camellia+%C3%97+williamsii+ETR+Carlyon&tbm=shop\n",
      "grid format\n",
      "[{'rhs_id': '60211', 'google_id_type': 'data-docid', 'google_id': '13494938336132702635', 'google_product_url': 'https://www.google.co.uk/shopping/product/1?prds=pid:13494938336132702635', 'query_date': '01-Apr-2021'}, {'rhs_id': '60211', 'google_id_type': 'data-docid', 'google_id': '5838886311669205989', 'google_product_url': 'https://www.google.co.uk/shopping/product/1?prds=pid:5838886311669205989', 'query_date': '01-Apr-2021'}]\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "nearby-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infile = 'testbuying.txt'\n",
    "    \n",
    "# read file\n",
    "#with open(infile, 'r') as f:\n",
    "#    indata=json.load(f)\n",
    "\n",
    "#df = pd.DataFrame(indata['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "hazardous-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
